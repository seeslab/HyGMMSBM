{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "The purpose of this code is to make predictions of unobserved binary hyperedges in a hypergraph with binary hyperedges.\n",
    "Note that the training contains data about all observations of hyperedges and non-hyperedges. \n",
    "Hyperedges in the test set should not appear in the training set neither as 1s nor as 0s in the adjacency matrix.\n",
    "\n",
    "There are two opstions of model (code) for which we give an implementation:\n",
    "\n",
    "    - a mixed-membership stochastic block model for hypergraphs in the Bernouilli formulation\n",
    "    \n",
    "    - a mixed-membership stochastic block model for hypergraphs in the Bernouilli formulation assuming an assortative connection probability matrix \n",
    "\n",
    "For both options we give two possible example implementations for both cases:\n",
    "\n",
    "    - Predictions using a single run of the EM algorithm\n",
    "    \n",
    "    - Predictions using several runs of the EM  algorithm so that probabilities for each hyperedge in the test set are the averages over probabilities of each model.\n",
    "\n",
    "To run this you should have installed python3 in your computer. The necessary modules are listed in the file requirements.txt\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the modules\n",
    "First we import the necessary modules and update sys.path to include our working directory (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "##add current directory to the path so that you can find the modules\n",
    "#sys.path+=['./'] \n",
    "from mmsbm import *\n",
    "import assortative as ast\n",
    "from random import seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data format for train and test files\n",
    "The input file (train.dat) should have a two-column format separated by a space ' ':\n",
    "\n",
    "First column: hyperedge, string concatenating the different labels of the nodes participating in the hyperedge with '_'\n",
    "\n",
    "Second column: 1/0 for edges and nonedges, respectively\n",
    "\n",
    "Example:\n",
    "\n",
    "sub1_sub2 0\n",
    "\n",
    "sub3_sub_4_sub5_sub7 1\n",
    "\n",
    "sub1_sub3_sub7 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input parameters\n",
    "You need to specify \n",
    "\n",
    "maxS - the largest hyperedge size\n",
    "\n",
    "cdin - directory wehre the input data is\n",
    "\n",
    "cdout - directory where the output files should go \n",
    "\n",
    "k - the number of latent groups in the MMSBM \n",
    "\n",
    "nruns - number of models to make predictions with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxS=3 ## maximum size of the hyperedges in the dataset - in the example 3\n",
    "cdin='./Data/' ##directory where to read the data from\n",
    "cdout='./Output/'##optional directory for saving output files\n",
    "k=3 ##latent dimension (number of groups)\n",
    "nruns=5 # number of times we run the EM algorithm to find different models and average over them to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed-Membership SBM for binary hypergraphs - Bernouilli formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions from single run of the EM algorithm Mixed-Membership SBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges in training [1000. 1000.]\n",
      "time elapsed: 9.093852043151855\n",
      "AUC 0.8887161413099083\n",
      "Theta [[1.18848410e-01 4.30793099e-01 4.50358492e-01]\n",
      " [4.36194464e-01 3.12132860e-06 5.63802415e-01]\n",
      " [6.37565198e-01 3.19261844e-01 4.31729587e-02]\n",
      " [3.88986061e-02 6.43323844e-01 3.17777550e-01]\n",
      " [8.30607944e-01 2.47102502e-03 1.66921031e-01]\n",
      " [4.99882257e-01 1.76156431e-01 3.23961311e-01]\n",
      " [9.80502681e-01 3.90975053e-03 1.55875683e-02]\n",
      " [4.60151868e-01 3.09589534e-01 2.30258598e-01]\n",
      " [6.79642564e-01 2.38401002e-01 8.19564342e-02]\n",
      " [3.68950761e-01 2.60107079e-01 3.70942160e-01]]\n",
      "Q - affinity tensor, for hyperedges of size 3\n",
      "0 0 0 [1. 0.]\n",
      "0 0 0 [1. 0.]\n",
      "0 0 0 [1. 0.]\n",
      "0 0 1 [1. 0.]\n",
      "0 0 1 [1. 0.]\n",
      "0 0 1 [1. 0.]\n",
      "0 0 2 [1. 0.]\n",
      "0 0 2 [1. 0.]\n",
      "0 0 2 [1. 0.]\n",
      "0 1 0 [1. 0.]\n",
      "0 1 0 [1. 0.]\n",
      "0 1 0 [1. 0.]\n",
      "0 1 1 [1. 0.]\n",
      "0 1 1 [0. 1.]\n",
      "0 1 1 [1. 0.]\n",
      "0 1 2 [1. 0.]\n",
      "0 1 2 [1. 0.]\n",
      "0 1 2 [1. 0.]\n",
      "0 2 0 [1. 0.]\n",
      "0 2 0 [1. 0.]\n",
      "0 2 0 [1. 0.]\n",
      "0 2 1 [1. 0.]\n",
      "0 2 1 [1. 0.]\n",
      "0 2 1 [1. 0.]\n",
      "0 2 2 [1. 0.]\n",
      "0 2 2 [1. 0.]\n",
      "0 2 2 [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "seed(1) ##just for control, this line can be commented\n",
    "\n",
    "fname = cdin+'train.dat'\n",
    "\n",
    "edges, nodes, n2id, sizes = ReadEdges(fname,maxS) ##I have to do it here to restart n2id\n",
    "\n",
    "print('Edges in training',sizes [2:])\n",
    "\n",
    "theta, q, l2ps, ups = InitializeParameters(nodes, maxS, k)\n",
    "\n",
    "logL0 = ComputeLikelihood(edges,theta,q,l2ps,sizes)\n",
    "\n",
    "max_iter=5000\n",
    "\n",
    "start_time1 = time.time()\n",
    "theta,q = ObtainEMPars(theta,q,nodes,edges,l2ps,max_iter,sizes)\n",
    "\n",
    "end_time1 = time.time()\n",
    "print(f\"time elapsed: {end_time1 - start_time1}\")\n",
    "\n",
    "logL = ComputeLikelihood(edges,theta,q,l2ps,sizes)\n",
    "\n",
    "outfile = cdout+'out_nonassort.dat' \n",
    "\n",
    "test_fname = cdin+'test.dat'\n",
    "\n",
    "predictions = MakePredictions(test_fname,n2id,theta,q,l2ps,outfile=outfile)\n",
    "\n",
    "auc = ComputeAUC(predictions)\n",
    "\n",
    "print('AUC',auc)\n",
    "print('Theta',theta[0:10])\n",
    "print('Q - affinity tensor, for hyperedges of size 3')\n",
    "##note that affinity tensors have to elements corespoding to (p[0],p[1])\n",
    "##since affinity tensors are flattened into a 1 dimensional array, we need to do some work to obtain the indices (kis)\n",
    "ss=3\n",
    "for ki in range(k**ss):\n",
    "    kis=[]\n",
    "    ki0=ki\n",
    "    for i in range(ss):\n",
    "        i1= int(ki0/k**(ss-i))\n",
    "        ki0-=i1*k**(ss-i)\n",
    "        kis.append(str(i1))\n",
    "    print(' '.join(kis),q[ss][ki])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions from averages over nruns of the EM algorithm for Mixed-Membership SBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges in training [   0.    0. 1000. 1000.]\n",
      "time elapsed: 8.919795989990234\n",
      "Rep 0 -1681.4732578403007 -0.005905945380862406 0.8887161413099083\n",
      "time elapsed: 9.597474813461304\n",
      "Rep 1 -1390.5699607575582 -0.006581726190664013 0.9023320082003582\n",
      "time elapsed: 10.103657007217407\n",
      "Rep 2 -1701.970605758891 -0.006132701990427036 0.922974700140461\n",
      "time elapsed: 9.73670768737793\n",
      "Rep 3 -1234.7962107078279 -0.005918033072432983 0.9359596555277835\n",
      "time elapsed: 10.46608304977417\n",
      "Rep 4 -1486.229416933768 -0.0055888301207673375 0.9091809958712922\n",
      "AUC 0.9569093225308581\n"
     ]
    }
   ],
   "source": [
    "seed(1) ## for control only \n",
    "\n",
    "fname = cdin+'train.dat'\n",
    "\n",
    "edges,nodes,n2id_ini,sizes = ReadEdges(fname,maxS)\n",
    "\n",
    "print('Edges in training',sizes)\n",
    "\n",
    "preds=[] ## Here we will store predictions for each \n",
    "\n",
    "for rep in range(nruns):\n",
    "\n",
    "    n2id=np.array([i for i in n2id_ini]) ##We need to restart n2id each time\n",
    "\n",
    "    theta, q, l2ps, ups = InitializeParameters(nodes, maxS, k)\n",
    "\n",
    "\n",
    "    logL0 = ComputeLikelihood(edges,theta,q,l2ps,sizes)\n",
    "\n",
    "    max_iter=5000\n",
    "\n",
    "    start_time1 = time.time()\n",
    "    theta,q = ObtainEMPars(theta,q,nodes,edges,l2ps,max_iter,sizes)\n",
    "\n",
    "    end_time1 = time.time()\n",
    "    print(f\"time elapsed: {end_time1 - start_time1}\")\n",
    "\n",
    "    logL = ComputeLikelihood(edges,theta,q,l2ps,sizes)\n",
    "\n",
    "    outfile = cdout+'out_nonassort_fold%d.dat' %(rep)\n",
    "\n",
    "    test_fname = cdin+'test.dat'\n",
    "    \n",
    "    predictions = MakePredictions(test_fname,n2id,theta,q,l2ps,outfile=None)\n",
    "\n",
    "    auct = ComputeAUC(predictions)\n",
    "\n",
    "    print('Rep',rep,logL0,logL,auct)\n",
    "    #print(theta[0])\n",
    "    #print(q[2])\n",
    "    preds.append(predictions)\n",
    "\n",
    "    \n",
    "    \n",
    "auc=ComputeAUCv(preds)\n",
    "print('AUC',auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assortative Mixed-Membership SBM for binary hypergraphs - Bernouilli formulation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions from single run of the EM algorithm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 break\n",
      "AUC 0.6700251889523441\n",
      "Theta\n",
      "[0. 1. 0.]\n",
      "[0. 1. 0.]\n",
      "[0. 1. 0.]\n",
      "[0. 1. 0.]\n",
      "[0. 1. 0.]\n",
      "[0. 1. 0.]\n",
      "[0. 1. 0.]\n",
      "[0. 1. 0.]\n",
      "[0. 1. 0.]\n",
      "[0. 1. 0.]\n",
      "Q - affinity tensor, for hyperedges of size 3\n",
      "0 [0. 1.]\n",
      "1 [0.98135718 0.01864282]\n",
      "2 [0.08039591 0.91960409]\n"
     ]
    }
   ],
   "source": [
    "seed(11)\n",
    "\n",
    "fname = cdin+'train.dat'\n",
    "\n",
    "edges,nodes,n2id = ast.ReadEdges(fname,maxS)\n",
    "##n2id is a list that keeps track of the relationship between internal ids for nodes and real labels form the string\n",
    "\n",
    "theta,q = ast.InitializeParameters(nodes,maxS,k)\n",
    "##model parameters at random\n",
    "\n",
    "logL0 = ast.ComputeLikelihood(edges,theta,q)\n",
    "\n",
    "max_iter = int(5000*sqrt(k))##maximum number of iterations, in cas the internal check is never fulfilled\n",
    "theta,q = ast.ObtainEMPars(theta,q,nodes,edges,max_iter)\n",
    "\n",
    "logL = ast.ComputeLikelihood(edges,theta,q)\n",
    "\n",
    "outfile = cdout+'output_assort.dat' #optional if you want to output model parameters\n",
    "\n",
    "test_fname = cdin+'test.dat'\n",
    "\n",
    "predictions = ast.MakePredictions(test_fname,n2id,theta,q,outfile=None)\n",
    "\n",
    "auc = ast.ComputeAUC(predictions)\n",
    "\n",
    "print('AUC',auc)\n",
    "print('Theta')\n",
    "for i in range(10):\n",
    "    print(theta[i])\n",
    "print('Q - affinity tensor, for hyperedges of size 3')\n",
    "##note that affinity tensors have to elements corespoding to (p[0],p[1])\n",
    "for i in range(k):\n",
    "    print(i,q[3][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions from averages over nruns of the EM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 break\n",
      "-5383.720933403015 -183.28239400599048 0.6700251889523441\n",
      "150 break\n",
      "-6085.242905112643 -179.5709855782157 0.6410579345349798\n",
      "200 break\n",
      "-4954.258627773241 -173.0033474536133 0.6863979849222416\n",
      "100 break\n",
      "-6840.319376662561 -177.09061947039268 0.54534005037423\n",
      "450 break\n",
      "-4401.408416110124 -329.30721940223617 0.4999999999614363\n",
      "AUC 0.6863979849222416\n"
     ]
    }
   ],
   "source": [
    "seed(11)\n",
    "\n",
    "fname = cdin+'train.dat'\n",
    "\n",
    "edges,nodes,n2id = ast.ReadEdges(fname,maxS)\n",
    "\n",
    "preds=[] ## Here we will store predictions for each \n",
    "\n",
    "for rep in range(nruns):\n",
    "\n",
    "    n2id=[i for i in n2id_ini] ##We need to restart n2id each time\n",
    "    theta,q= ast.InitializeParameters(nodes,maxS,k)\n",
    "    logL0=ast.ComputeLikelihood(edges,theta,q)\n",
    "    max_iter=int(5000*sqrt(k))##maximum number of iterations, in cas the internal check is never fulfilled\n",
    "    theta,q=ast.ObtainEMPars(theta,q,nodes,edges,max_iter)\n",
    "    logL=ast.ComputeLikelihood(edges,theta,q)\n",
    "    outfile= cdout+'output%d.dat' %(rep) #optional if you want to output model parameters\n",
    "    test_fname = cdin+'test.dat'\n",
    "    predictions= ast.MakePredictions(test_fname,n2id,theta,q,outfile=None)\n",
    "    auct=ast.ComputeAUC(predictions)\n",
    "    print(logL0,logL,auct) ##print out likelihoods and the auc for this particular model\n",
    "    preds.append(predictions)\n",
    "\n",
    "auc=ast.ComputeAUCv(preds) ##Compute auc by averaging prediction scores over models\n",
    "print('AUC',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
